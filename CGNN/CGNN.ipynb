{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1142d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No IPv4 address found on en5 !\n",
      "WARNING: No IPv4 address found on ap1 !\n",
      "WARNING: more No IPv4 address found on awdl0 !\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy\n",
    "import scapy.plist\n",
    "from scapy.all import *\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scapy.layers.inet import TCP, Ether, IP, UDP\n",
    "from scapy.layers.dns import DNS\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783f7762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SgcLayer(tfk.layers.Layer):\n",
    "    def __init__(self, outputsNumber):\n",
    "        super(SgcLayer, self).__init__()\n",
    "        self.outputs = outputsNumber\n",
    "        pass\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.teta = self.add_weight(\"teta\",\n",
    "                                    shape=[input_shape[-1],self.outputs],\n",
    "                                    trainable=True,\n",
    "                                    initializer=\"random_normal\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.relu(tf.matmul(inputs, self.teta))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27848751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cgnn_model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(cgnn_model, self).__init__()\n",
    "        self.sgc1 = SgcLayer(516)\n",
    "        self.sgc2 = SgcLayer(256)\n",
    "        self.dense = tf.keras.layers.Dense(6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.sgc1(inputs)\n",
    "        x = self.sgc2(x)\n",
    "        x = tf.keras.layers.AveragePooling1D(strides=1, pool_size=(inputs.shape[1]))(x)\n",
    "        x = self.dense(x)\n",
    "        x = tf.nn.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32acea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_diagonal_degree(A):\n",
    "    D = np.zeros((len(A), len(A)))\n",
    "    for i in range(len(A)):\n",
    "        D[i][i] = np.sum(A[i])\n",
    "    return D\n",
    "\n",
    "\n",
    "def sum_matrices(A, B):\n",
    "    result = np.array([[0 for x in range(len(A))] for y in range(len(A))])\n",
    "    for i in range(len(A)):\n",
    "        # iterate through columns\n",
    "        for j in range(len(A[0])):\n",
    "            result[i][j] = A[i][j] + B[i][j]\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "def normalize_D_t(D_t):\n",
    "    for i in range(len(D_t)):\n",
    "        D_t[i][i] = 1 / np.sqrt(D_t[i][i])\n",
    "    return D_t\n",
    "\n",
    "\n",
    "def normalize_A_t(A_t):\n",
    "    for i in range(len(A_t)):\n",
    "        for j in range(len(A_t[0])):\n",
    "            if A_t[i][j] != 0:\n",
    "                A_t[i][j] = 1 / np.sqrt(A_t[i][j])\n",
    "    return A_t\n",
    "\n",
    "\n",
    "def convertListToArray(Array):\n",
    "    new_A = np.empty([len(Array), 1500])\n",
    "    for i in range(len(Array)):\n",
    "        np.append(new_A, np.array(Array[i]))\n",
    "    return new_A\n",
    "\n",
    "def getSX(session):\n",
    "    X = convertListToArray(session)\n",
    "    A = calculate_A(session)\n",
    "    I = np.identity(len(A[0]))\n",
    "    A_t = sum_matrices(A, I)\n",
    "    D_t = np.array(get_diagonal_degree(A_t))\n",
    "    D_t = normalize_D_t(D_t)\n",
    "    A_t = normalize_A_t(A_t)\n",
    "    S_temp = np.dot(D_t, A_t)\n",
    "    S = np.dot(S_temp, D_t)\n",
    "    X = X.astype(float)\n",
    "    SX = np.dot(S, X)\n",
    "    return np.asarray(SX)\n",
    "\n",
    "\n",
    "def complete(s, l=1500):\n",
    "    return [i for i in s] + [0] * (l - len(s))\n",
    "\n",
    "\n",
    "def calculate_A(session):\n",
    "    X = session\n",
    "    A = []\n",
    "    for i in range(len(X)):\n",
    "        temp = []\n",
    "        for j in range(len(X)):\n",
    "            if i == j + 1 or i == j - 1:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        A.append(temp)\n",
    "    return np.array(A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db71882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraphFromSession(pcapName):\n",
    "    file = rdpcap(\"data/w_hi_chrome/\" + pcapName)\n",
    "    l = []\n",
    "    for p in file:\n",
    "        packet_proc = preprocessing(p)\n",
    "        if packet_proc:\n",
    "            if complete(packet_proc):\n",
    "                l.append(complete(packet_proc))\n",
    "    return getSX(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aebe1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(packet):\n",
    "    if packet.haslayer(IP):\n",
    "        packet[IP].src = 0\n",
    "        packet[IP].dst = 0\n",
    "        if packet.haslayer(TCP):\n",
    "            FIN = 0x01\n",
    "            SYN = 0x02\n",
    "            ACK = 0x10\n",
    "            F = packet['TCP'].flags  # this should give you an integer\n",
    "            if F & FIN or F & SYN or F & ACK or packet.haslayer(DNS):\n",
    "                if len(packet) <= 66:\n",
    "                    return None\n",
    "\n",
    "            w_eth_header = bytes(packet)[14:]\n",
    "            return w_eth_header\n",
    "        elif packet.haslayer(UDP):\n",
    "            w_eth_header = bytes(packet)[14:]\n",
    "            zero_bytes = bytearray(12)\n",
    "            new_packet = bytes(w_eth_header[:8]) + zero_bytes + bytes(w_eth_header[8:])\n",
    "            return new_packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eeede62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getTrainTestGraphs():\n",
    "    df = pd.read_csv(\"data/w_hi_chrome/id.csv\")\n",
    "    train_name, test_name, train_label, test_label = train_test_split(df[\"fname\"],\n",
    "                                                                      df[\"label\"],\n",
    "                                                                      test_size=0.98,\n",
    "                                                                      random_state=42)\n",
    "    GraphsForTrain = []\n",
    "    GraphsForTest = []\n",
    "\n",
    "    for i in train_name:\n",
    "        g = createGraphFromSession(i)\n",
    "\n",
    "        GraphsForTrain.append(np.ndarray.tolist(g))\n",
    "\n",
    "    LableForTrain = []\n",
    "    for i in train_label:\n",
    "        LableForTrain.append(int(i))\n",
    "\n",
    "    counter = 0\n",
    "    for name in df[\"fname\"]:\n",
    "        print(\"its here\")\n",
    "        if name not in train_name:\n",
    "            g = createGraphFromSession(name)\n",
    "\n",
    "            counter += 1\n",
    "            GraphsForTest.append(g)\n",
    "            if counter == 10:\n",
    "                break\n",
    "\n",
    "    return GraphsForTrain, list(LableForTrain), GraphsForTest, list(test_label[:10])  # the graphs is SX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99990fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/5xpq5b7j45b21f9qt43jm7jr0000gn/T/ipykernel_25305/2498967240.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array(session)\n"
     ]
    }
   ],
   "source": [
    "GraphsForTrain, LabelsForTrain, GraphsForTest, LabelsForTest = getTrainTestGraphs()\n",
    "m = cgnn_model()\n",
    "m.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "max_n = max([len(i) for i in GraphsForTrain])\n",
    "for g in GraphsForTrain:\n",
    "    zeros = [0] * 1500\n",
    "    for i in range(max_n - len(g)):\n",
    "        g.append(zeros)\n",
    "\n",
    "graph_to_train = tf.convert_to_tensor(GraphsForTrain,tf.float32)\n",
    "graph_to_train = tf.cast(graph_to_train, tf.float32)\n",
    "\n",
    "dict_label = {}\n",
    "counter = 0\n",
    "for item in set(LabelsForTrain):\n",
    "    dict_label[item] = counter\n",
    "    counter += 1\n",
    "\n",
    "dict_label[18102.0] = 5 # remove this when i will train on big data!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "list_of_lables = []\n",
    "for item in LabelsForTrain:\n",
    "    list_temp = [0] * 6\n",
    "    list_temp[dict_label[item]] = 1\n",
    "    list_of_lables.append(list_temp)\n",
    "\n",
    "label_graph_to_train = tf.convert_to_tensor(list_of_lables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7462a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(graph_to_train, np.reshape(label_graph_to_train, (65, 1, 6)), epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c148ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lables_test = []\n",
    "for item in LabelsForTest[:10]:\n",
    "    list_temp = [0] * 6\n",
    "    list_temp[dict_label[item]] = 1\n",
    "\n",
    "    list_of_lables_test.append(list_temp)\n",
    "for g in GraphsForTest[:10]:\n",
    "    zeros = [0] * 1500\n",
    "    for i in range(max_n - len(g)):\n",
    "        np.append(g, zeros)\n",
    "graph_to_test = tf.convert_to_tensor(GraphsForTrain[:10], tf.float32)\n",
    "graph_to_test = tf.cast(graph_to_test, tf.float32)\n",
    "\n",
    "m.evaluate(graph_to_test, np.reshape(list_of_lables_test[:10], (10, 1, 6)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
